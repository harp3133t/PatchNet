{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0055997-301e-4097-b71b-cc2e323334e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import *\n",
    "from Stack_LIME import *\n",
    "from coordconv import *\n",
    "\n",
    "import glob\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "torch.manual_seed(17)\n",
    "tf = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286de8b0-1283-4a86-8b02-db33799819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(name):\n",
    "    try:\n",
    "        if not os.path.exists(name):\n",
    "            os.makedirs(name)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f542d33b-3268-4e6a-84ef-34bf704bdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16db64b8-a0fe-42e7-918d-c0544dcf7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(LightningModule):\n",
    "    def __init__(self, batch_size = 200, num_workers = 0, train_dataset = None,\n",
    "    test_dataset = None):\n",
    "        super().__init__()\n",
    "        self.model = resnet18(pretrained=False, progress=True, device=\"cuda\")\n",
    "#         self.model = torchvision.models.squeezenet1_1()\n",
    "#         self.model.features[0] = nn.Sequential(CoordConv2d(3, 32, 1, with_r=True),nn.Conv2d(32,64,3))\n",
    "#         self.model.classifier[1] = nn.Conv2d(512, 10, 1, 1)\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.metrics = torchmetrics.Accuracy()\n",
    "        \n",
    "    def restart(self, batch_size = 200, num_workers = 0, train_dataset = None,test_dataset = None):\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.metrics = torchmetrics.Accuracy()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.metrics(logits, y)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.metrics(logits, y)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            dataset = self.train_dataset\n",
    "            dataset_size = dataset.__len__()\n",
    "            self.train_ds, self.val_ds = random_split(dataset, [int(dataset_size * 0.9) , int(dataset_size * 0.1)])\n",
    "\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_ds = self.test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers = self.num_workers, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers = self.num_workers, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers = self.num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019ff27c-32d8-440e-af9c-8681a676f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_edit(Dataset):\n",
    "    def __init__(self, img_dir, labels, transform = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = glob.glob(img_dir+'/*')\n",
    "        self.img = []\n",
    "        for k in self.img_labels:\n",
    "            imgs = glob.glob(k + '/*')\n",
    "            self.img += imgs\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        image = np.array(image)\n",
    "\n",
    "        label = img_path.split('/')\n",
    "        label = label[2].split('\\\\')[1]\n",
    "        label = self.labels[label]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc7074bd-cbc7-4f15-91c3-edb6da31b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "unorm = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f97c8922-2605-4383-a25c-6d043f2b02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['airplane', 'automobile', 'bird','cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# train_data = CIFAR10_edit('./data/edit_img_b', labels = labels, transform = transform)\n",
    "train_data = CIFAR10('./data/cifar10', train = True, download = False, transform = transform)\n",
    "\n",
    "test_data = CIFAR10('./data/cifar10', train = False, download = False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be6027d-1f8b-4048-9cda-08686f11b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(batch_size = 512, num_workers = 0 ,\n",
    "            train_dataset = train_data, test_dataset = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e57b1ee-ebb3-468d-ac6c-4a79749120e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = \"./model/resnet18_orig_split.ckpt\"\n",
    "model = model.load_from_checkpoint(chk_path)\n",
    "model.restart(batch_size = 512, num_workers = 8 ,\n",
    "            train_dataset = train_data, test_dataset = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fdb1c9-a726-42b3-a7cb-a8ef6791e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator = 'gpu', devices = 1 , max_epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd54cbc-5d92-4c8d-a69f-220f6a7414ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912aa81a33b54786aa4c64f79eaba588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jh\\anaconda3\\envs\\ispin\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.37299999594688416, 'test_loss': 7.9693827629089355}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.37299999594688416, 'test_loss': 7.9693827629089355}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setup(None)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c9df6c0-1f56-41f4-ae87-8054d59b67d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3246108a8eb5447eb69a8ddc4ffc96a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.9240000247955322, 'val_loss': 0.2444816678762436}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_acc': 0.9240000247955322, 'val_loss': 0.2444816678762436}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setup('fit')\n",
    "trainer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f12a0-6a6f-4c4a-8d6a-d99e682f8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3,4,5]])\n",
    "# a.append(torch.tensor([1,2,3,6,7]))\n",
    "# a.append(torch.tensor([5,3,4,2,4]))\n",
    "print(a)\n",
    "c = torch.stack(a, dim =1)\n",
    "# c = torch.stack([c,d], dim = 0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0b71d-2c6e-4971-abb3-90db3703bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5d46a-db71-43ba-b16b-62e52eff7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf115ca9-8a85-4e72-a220-cd1dad6b2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc63b8-17a7-4018-a8b2-4ff57e25b6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
