{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0055997-301e-4097-b71b-cc2e323334e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import *\n",
    "from Stack_LIME import *\n",
    "from coordconv import *\n",
    "\n",
    "import glob\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "torch.manual_seed(17)\n",
    "tf = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286de8b0-1283-4a86-8b02-db33799819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(name):\n",
    "    try:\n",
    "        if not os.path.exists(name):\n",
    "            os.makedirs(name)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f542d33b-3268-4e6a-84ef-34bf704bdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da152e6-40bb-4717-9a7f-d9e5e98504da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['a','b','c']\n",
    "a.index('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16db64b8-a0fe-42e7-918d-c0544dcf7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(LightningModule):\n",
    "    def __init__(self, batch_size = 200, num_workers = 0, train_dataset = None,\n",
    "    test_dataset = None):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.squeezenet1_1()\n",
    "        self.model.features[0] = nn.Sequential(CoordConv2d(3, 32, 1, with_r=True),nn.Conv2d(32,64,3))\n",
    "        self.model.classifier[1] = nn.Conv2d(512, 10, 1, 1)\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.metrics = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.metrics(logits, y)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = []\n",
    "        for img in x:\n",
    "            img = np.array(img)\n",
    "            channel, width,height = img.shape\n",
    "            half_width = int(width/2)\n",
    "            half_height = int(height/2)\n",
    "            img_list_4 = [img[:, :half_width, :half_height],\n",
    "                img[:, half_width:, :half_height],\n",
    "                img[:, :half_width, half_height:],\n",
    "                img[:, half_width:, half_height:]]\n",
    "            q = []\n",
    "            for split_img in img_list_4:\n",
    "                q.append(self(img_list_4[0]))\n",
    "            logits.append(np.sum(q))\n",
    "        \n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.metrics(logits, y)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            dataset = self.train_dataset\n",
    "            dataset_size = dataset.__len__()\n",
    "            self.train_ds, self.val_ds = random_split(dataset, [int(dataset_size * 0.9) , int(dataset_size * 0.1)])\n",
    "\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_ds = self.test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers = self.num_workers, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers = self.num_workers, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers = self.num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56c8a6d-5b62-4a54-954e-809fec7b0976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.cpu_count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "019ff27c-32d8-440e-af9c-8681a676f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_edit(Dataset):\n",
    "    def __init__(self, img_dir, labels, transform = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = glob.glob(img_dir+'/*')\n",
    "        self.img = []\n",
    "        for k in self.img_labels:\n",
    "            imgs = glob.glob(k + '/*')\n",
    "            self.img += imgs\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img[idx]\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        image = np.array(image)\n",
    "\n",
    "        label = img_path.split('/')\n",
    "\n",
    "        label = self.labels.index(label[3])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc7074bd-cbc7-4f15-91c3-edb6da31b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "unorm = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f97c8922-2605-4383-a25c-6d043f2b02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['airplane', 'automobile', 'bird','cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_data = CIFAR10_edit('./data/edit_img_b', labels = labels, transform = transform)\n",
    "test_data = CIFAR10('./data/cifar10', train = False, download = False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8be6027d-1f8b-4048-9cda-08686f11b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(batch_size = 512, num_workers = 16 ,\n",
    "            train_dataset = train_data, test_dataset = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4fdb1c9-a726-42b3-a7cb-a8ef6791e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator = 'gpu', devices = 1 , max_epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1501ec3-f197-4df2-aa7c-17188bd90c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/harp3133t/바탕화면/Research/PatchNet/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | model   | SqueezeNet | 744 K \n",
      "1 | metrics | Accuracy   | 0     \n",
      "---------------------------------------\n",
      "744 K     Trainable params\n",
      "0         Non-trainable params\n",
      "744 K     Total params\n",
      "2.979     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc576a4a577d4b03810914a01b77db66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harp3133t/anaconda3/envs/ispin/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd54cbc-5d92-4c8d-a69f-220f6a7414ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
