{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6c6f13-edc7-467c-a6f4-18d1065fab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import *\n",
    "from Stack_LIME import *\n",
    "from coordconv import *\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "torch.manual_seed(17)\n",
    "tf = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581ca498-e29c-4f50-a8dc-c84163a841ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(name):\n",
    "    try:\n",
    "        if not os.path.exists(name):\n",
    "            os.makedirs(name)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb980e99-39fe-4555-846a-60791a927eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651e890-fb8a-43bb-8fbb-59b03c1259ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True, progress=True, device=\"cuda\")\n",
    "#model\n",
    "model.conv1 = nn.Sequential(CoordConv2d(3, 32, 1, with_r=True),nn.Conv2d(32,64,3))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59598e66-cade-4e18-98ee-5877b0f752d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(LightningModule):\n",
    "    def __init__(self, batch_size = 200, num_workers = 0, train_dataset = None,\n",
    "    test_dataset = None):\n",
    "        super().__init__()\n",
    "        self.model = resnet50(pretrained=False, progress=True, device=\"cuda\")\n",
    "        #self.model.conv1 = nn.Sequential(CoordConv2d(3, 32, 1, with_r=True),nn.Conv2d(32,64,3))\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.metrics = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.metrics(logits, y)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = self.metrics(logits, y)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            dataset = self.train_dataset\n",
    "            dataset_size = dataset.__len__()\n",
    "            self.train_ds, self.val_ds = random_split(dataset, [int(dataset_size * 0.9) , int(dataset_size * 0.1)])\n",
    "\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_ds = self.test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers = self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers = self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers = self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05a94abd-13ff-4c45-83df-394e23c08b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "unorm = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af603f55-1f0a-4573-83e8-1cdaed8315ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CIFAR10('./data/cifar10', train = True, download = False, transform = transform)\n",
    "test_data = CIFAR10('./data/cifar10', train = False, download = False, transform = transform)\n",
    "labels = ['airplane', 'automobile', 'bird','cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d696ad64-49bd-44e1-a8b7-ad07a102acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(batch_size = 512, num_workers = 0 ,\n",
    "            train_dataset = train_data, test_dataset = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81a76d14-61c6-400c-8e82-d1683d9ae65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator = 'gpu', devices = 1 , max_epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ad90a60-d64c-4513-a056-12e04381ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2866f9316f4a4f5982b1e979c8c86c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.18000000715255737, 'test_loss': 3.6212196350097656}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.18000000715255737, 'test_loss': 3.6212196350097656}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setup(None)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041b166d-5c88-456c-8663-22e28182cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\users\\jh\\anaconda3\\envs\\ispin\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c134d66e07b642cca918e41f68528cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.9351999759674072, 'val_loss': 0.22464138269424438}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_acc': 0.9351999759674072, 'val_loss': 0.22464138269424438}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setup('fit')\n",
    "trainer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceeb0fef-6309-41bc-80f6-ff3ca631786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded . . . \n",
      "Device is a cuda:0. . . \n",
      "transform setting finish . . .\n",
      "Clear!\n"
     ]
    }
   ],
   "source": [
    "stack_xai = Stack_XAI(model, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8cd2553-c942-4def-aaa4-a34c65f8c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████▉| 49983/50000 [3:36:02<00:04,  3.73it/s]c:\\users\\jh\\anaconda3\\envs\\ispin\\lib\\site-packages\\lime\\wrappers\\scikit_image.py:117: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  return self.target_fn(args[0], **self.target_params)\n",
      "IOPub message rate exceeded.##########################################        |\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for x, y in tqdm.tqdm(train_data):\n",
    "    x = tf(unorm(x))\n",
    "    m = stack_xai.explain(x, XAI = 'LIME', n_seg = 100, n_samples = 100)\n",
    "    xai_img = stack_xai.get_mask_image(x, m)\n",
    "    xai_img = Image.fromarray(xai_img)\n",
    "    create_folder('./data/edit_img_b/'+ labels[y])\n",
    "    xai_img.save('./data/edit_img_b/'+ labels[y] + '/' + str(n) + '.jpg')\n",
    "    n += 1\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c0592e9-605a-474b-90f9-864b73878695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frog': 0.9865164756774902,\n",
       " 'cat': 0.003206209046766162,\n",
       " 'bird': 0.001991337863728404,\n",
       " 'dog': 0.0015933840768411756,\n",
       " 'deer': 0.0014924925053492188,\n",
       " 'airplane': 0.0010641058906912804,\n",
       " 'ship': 0.001064022770151496,\n",
       " 'truck': 0.0010457603493705392,\n",
       " 'horse': 0.0010206550359725952,\n",
       " 'automobile': 0.0010056134779006243}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_data[0]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    #batch = torch.stack(tuple(transform(i) for i in img), dim=0)\n",
    "    #batch = batch.to(self.device)\n",
    "    logits = model(transform(tf(unorm(x))).cuda().unsqueeze(0))\n",
    "    output = F.softmax(logits, dim=1)\n",
    "    output = output.detach().cpu().numpy()\n",
    "score, label = torch.topk(torch.Tensor(output), 10)\n",
    "label = label.squeeze_()\n",
    "dict_prob = {}\n",
    "for i in range(10):\n",
    "    label_name = labels[label[i].item()]\n",
    "    dict_prob[label_name] = score[0][i].item()\n",
    "dict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc2188ea-299e-4cee-bea3-9a2412caadb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea4726-9e8f-4763-80d8-9e03acaf74ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
